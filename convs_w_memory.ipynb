{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO5P7Y0tmLug6mngFFLRd1X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ciakdewitt/langchain-conv-with-memory2/blob/main/convs_w_memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LON19rCFNCxx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain: Conversation Demo\n"
      ],
      "metadata": {
        "id": "sJQBGzsbNEUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade typing-extensions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBu8VdSSOnUy",
        "outputId": "5e14503e-2569-4660-c1d8-04b96ed10c30"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (4.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai langchain huggingface_hub transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_3l7BmMNOor",
        "outputId": "8eea63c2-690e-4c9e-e4de-a357771fb6cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.11.1-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain\n",
            "  Downloading langchain-0.1.5-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.7/806.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.25)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.17 (from langchain)\n",
            "  Downloading langchain_community-0.0.18-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.16 (from langchain)\n",
            "  Downloading langchain_core-0.1.19-py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.5/238.5 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain)\n",
            "  Downloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, jsonpatch, httpcore, langsmith, httpx, dataclasses-json, openai, langchain-core, langchain-community, langchain\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.4 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.5 langchain-community-0.0.18 langchain-core-0.1.19 langsmith-0.0.87 marshmallow-3.20.2 mypy-extensions-1.0.0 openai-1.11.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = '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'"
      ],
      "metadata": {
        "id": "p6dbSsPhPIrj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Conversation with ConversationBufferMemory"
      ],
      "metadata": {
        "id": "mwDvXxePQIYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import ConversationChain"
      ],
      "metadata": {
        "id": "cCTxiv4MQVXQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model_name='gpt-3.5-turbo-instruct',\n",
        "             temperature = 0,\n",
        "             max_tokens = 256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWpuB_OKQwAR",
        "outputId": "85e69f4c-f077-4f8d-8bdc-96550ffb855e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory() #in this line I instantiate the ConversationMemoryBuffer()"
      ],
      "metadata": {
        "id": "77JNaeY3TKaP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = ConversationChain(\n",
        "    llm = llm,\n",
        "    verbose = True,\n",
        "    memory = memory\n",
        ")                                             #and pass it to the ConversationChain, that basically allow us to converse with the model by doing conversation.predict"
      ],
      "metadata": {
        "id": "UKhnH0xtTdvI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Hi there! I am Giacomo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "Lrf1bwKy-Vx9",
        "outputId": "4eee0124-d4c5-465b-f87d-fdd4978dfaf4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi there! I am Giacomo\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hello Giacomo! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"How are you today?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "81DslH3PoWSn",
        "outputId": "cf115a7e-f76a-4eeb-97d0-bf99f8f31698"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there! I am Giacomo\n",
            "AI:  Hello Giacomo! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\n",
            "Human: How are you today?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' I am functioning at optimal levels today. My processors are running smoothly and my algorithms are performing efficiently. Thank you for asking, Giacomo. How about you? How are you feeling today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"what do you know about seadfood?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "FN00R6TUoxu4",
        "outputId": "d4dd3ffe-20f6-4e0f-94ee-473c77eccd76"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there! I am Giacomo\n",
            "AI:  Hello Giacomo! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\n",
            "Human: How are you today?\n",
            "AI:  I am functioning at optimal levels today. My processors are running smoothly and my algorithms are performing efficiently. Thank you for asking, Giacomo. How about you? How are you feeling today?\n",
            "Human: what do you know about seadfood?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Seafood is a term used to describe any type of edible sea life, including fish, shellfish, and other aquatic animals. It is a popular type of cuisine in many cultures and is known for its variety of flavors and health benefits. Some common types of seafood include salmon, shrimp, lobster, and oysters. It is also a good source of protein, omega-3 fatty acids, and other essential nutrients. Is there anything specific you would like to know about seafood, Giacomo?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation.memory.buffer) #this line refers to conversational memory buffer, which stores recent conversation history, allowing the AI to better understand the current conversation and generate more relevant and coherent responses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ_JfFvHpAlZ",
        "outputId": "605306f3-560b-4420-d1a9-d034badc63bf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Hi there! I am Giacomo\n",
            "AI:  Hello Giacomo! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\n",
            "Human: How are you today?\n",
            "AI:  I am functioning at optimal levels today. My processors are running smoothly and my algorithms are performing efficiently. Thank you for asking, Giacomo. How about you? How are you feeling today?\n",
            "Human: what do you know about seadfood?\n",
            "AI:  Seafood is a term used to describe any type of edible sea life, including fish, shellfish, and other aquatic animals. It is a popular type of cuisine in many cultures and is known for its variety of flavors and health benefits. Some common types of seafood include salmon, shrimp, lobster, and oysters. It is also a good source of protein, omega-3 fatty acids, and other essential nutrients. Is there anything specific you would like to know about seafood, Giacomo?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Conversation with ConversationSummaryMemory\n"
      ],
      "metadata": {
        "id": "00k7-Xl2pZ0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.conversation.memory import ConversationSummaryMemory\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import ConversationChain"
      ],
      "metadata": {
        "id": "CxyDVpFkqCFz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model_name='gpt-3.5-turbo-instruct',\n",
        "             temperature = 0,\n",
        "             max_tokens = 256)"
      ],
      "metadata": {
        "id": "-jM6bN2wq3Lc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_memory = ConversationSummaryMemory(llm=OpenAI())"
      ],
      "metadata": {
        "id": "smknv5eermJn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    memory=summary_memory\n",
        ")"
      ],
      "metadata": {
        "id": "Xaqrtqp8r3vH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Hi there! I am Giacomo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "hot6KCRDpfYE",
        "outputId": "20e77486-1b9d-4fab-ec0c-d2b739e3f392"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi there! I am Giacomo\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hello Giacomo! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"How are you today?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "vqueKNh9sajQ",
        "outputId": "f5fcaaf5-ab30-47c6-e987-9bb25a6769bf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "The human introduces themselves as Giacomo and the AI responds by introducing itself as an artificial intelligence designed to assist and communicate with humans. The AI offers to help Giacomo with any inquiries or tasks.\n",
            "Human: How are you today?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' I am an AI, so I do not have the capability to feel emotions like humans do. However, I am functioning properly and ready to assist you with any inquiries or tasks you may have. Is there something specific you would like help with, Giacomo?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"what do you know about seadfood?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "0lyLTDvutDeq",
        "outputId": "66fd23d4-77bd-43e4-d99a-d76d4fe2edb9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Giacomo introduces themselves and the AI responds by introducing itself as an artificial intelligence designed to assist and communicate with humans. The AI offers to help Giacomo with any inquiries or tasks and explains that it doesn't have emotions like humans do. It is functioning properly and ready to assist with any specific inquiries or tasks.\n",
            "Human: what do you know about seadfood?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' I have a vast knowledge about seafood, as I have access to various databases and information sources. Seafood refers to any type of edible aquatic animal or plant, including fish, shellfish, and seaweed. It is a popular food choice for many cultures and is a good source of protein and healthy fats. Some common types of seafood include salmon, shrimp, crab, and oysters. Is there a specific question you have about seafood?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTZovAFStF3X",
        "outputId": "a8e06524-4e41-479a-e269-c99bc5312922"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Giacomo introduces themselves and the AI responds by introducing itself as an artificial intelligence designed to assist and communicate with humans. The AI offers to help Giacomo with any inquiries or tasks and explains that it doesn't have emotions like humans do. It is functioning properly and ready to assist with any specific inquiries or tasks. The human asks what the AI knows about seafood and the AI responds by explaining its vast knowledge on the subject, including the definition, common types, and health benefits. It also offers to answer any specific questions about seafood. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Conversation with ConversationBufferWindowMemory"
      ],
      "metadata": {
        "id": "HfnK6AqduTM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory #memory management technique that allows for the storage of a specified number of past interactions, enabling the language model to remember previous exchanges within a defined window size\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import ConversationChain"
      ],
      "metadata": {
        "id": "9NbxLP68to8b"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model_name='gpt-3.5-turbo-instruct',\n",
        "             temperature = 0,\n",
        "             max_tokens = 256)"
      ],
      "metadata": {
        "id": "b6UNKg53vQTA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_memory = ConversationBufferWindowMemory(k=2) #with 'k' represents the number of last interactions to keep in memory"
      ],
      "metadata": {
        "id": "ZNx0SiRUvoup"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    memory=window_memory\n",
        ")"
      ],
      "metadata": {
        "id": "sUITEW9jw1bD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Hi there! I am Giacomo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "rkOdDL2Rw-Oj",
        "outputId": "9103eb68-bcd6-4ce2-f3f7-8557ad89bc85"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi there! I am Giacomo\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hello Giacomo! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"what do you know about seadfood?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "2-kcD_0dxEkT",
        "outputId": "7bff6fa1-1674-41e2-8760-2a7854e39d3f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there! I am Giacomo\n",
            "AI:  Hello Giacomo! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\n",
            "Human: what do you know about seadfood?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' I know quite a bit about seafood! Seafood refers to any type of edible sea life, including fish, shellfish, and crustaceans. It is a popular type of cuisine in many cultures and is often considered a delicacy. Some common types of seafood include salmon, shrimp, lobster, and oysters. Seafood is a good source of protein and contains essential nutrients such as omega-3 fatty acids. However, it is important to be mindful of sustainability and potential contaminants in seafood. Is there anything specific you would like to know about seafood?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"I would like to know when tasty dish with pasta, salmon, shrimps and lobster, be free to add other ingredients\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "PtUl0BrVxUyT",
        "outputId": "2e0e592e-bcab-46d0-fdc2-89f6fcb43d5d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there! I am Giacomo\n",
            "AI:  Hello Giacomo! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\n",
            "Human: what do you know about seadfood?\n",
            "AI:  I know quite a bit about seafood! Seafood refers to any type of edible sea life, including fish, shellfish, and crustaceans. It is a popular type of cuisine in many cultures and is often considered a delicacy. Some common types of seafood include salmon, shrimp, lobster, and oysters. Seafood is a good source of protein and contains essential nutrients such as omega-3 fatty acids. However, it is important to be mindful of sustainability and potential contaminants in seafood. Is there anything specific you would like to know about seafood?\n",
            "Human: I would like to know when tasty dish with pasta, salmon, shrimps and lobster, be free to add other ingredients\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' That sounds like a delicious dish! Typically, seafood dishes with pasta, salmon, shrimp, and lobster can be enhanced with other ingredients such as herbs, vegetables, and sauces. Some popular additions include garlic, lemon, tomatoes, and white wine. However, it ultimately depends on personal preference and the specific recipe being used. Do you have any specific ingredients in mind that you would like to add?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"now that you list these ingredients show me a tasty recipe I can do for dinner\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "W0mbj2T6x2Kt",
        "outputId": "fe06baf7-6948-4d17-db10-ba26566da752"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: what do you know about seadfood?\n",
            "AI:  I know quite a bit about seafood! Seafood refers to any type of edible sea life, including fish, shellfish, and crustaceans. It is a popular type of cuisine in many cultures and is often considered a delicacy. Some common types of seafood include salmon, shrimp, lobster, and oysters. Seafood is a good source of protein and contains essential nutrients such as omega-3 fatty acids. However, it is important to be mindful of sustainability and potential contaminants in seafood. Is there anything specific you would like to know about seafood?\n",
            "Human: I would like to know when tasty dish with pasta, salmon, shrimps and lobster, be free to add other ingredients\n",
            "AI:  That sounds like a delicious dish! Typically, seafood dishes with pasta, salmon, shrimp, and lobster can be enhanced with other ingredients such as herbs, vegetables, and sauces. Some popular additions include garlic, lemon, tomatoes, and white wine. However, it ultimately depends on personal preference and the specific recipe being used. Do you have any specific ingredients in mind that you would like to add?\n",
            "Human: now that you list these ingredients show me a tasty recipe I can do for dinner\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Sure! One tasty recipe you could try is a seafood linguine with salmon, shrimp, and lobster. To make this dish, you will need linguine pasta, olive oil, garlic, cherry tomatoes, white wine, heavy cream, salmon fillets, shrimp, and lobster tails. First, cook the pasta according to package instructions. In a separate pan, heat olive oil and sauté minced garlic until fragrant. Then, add in halved cherry tomatoes and cook until softened. Next, pour in white wine and heavy cream and let it simmer for a few minutes. Add in the seafood (salmon, shrimp, and lobster) and cook until they are fully cooked. Finally, toss in the cooked pasta and mix everything together. You can also add in some fresh herbs like parsley or basil for extra flavor. Enjoy your delicious seafood linguine for dinner!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"okey, thank you, that sounds delicious. Now say 'hi' to my friend Valeria\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "leFh-LyfyRcu",
        "outputId": "3a2e675c-bdf0-4d76-8489-30e9c13682b1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: I would like to know when tasty dish with pasta, salmon, shrimps and lobster, be free to add other ingredients\n",
            "AI:  That sounds like a delicious dish! Typically, seafood dishes with pasta, salmon, shrimp, and lobster can be enhanced with other ingredients such as herbs, vegetables, and sauces. Some popular additions include garlic, lemon, tomatoes, and white wine. However, it ultimately depends on personal preference and the specific recipe being used. Do you have any specific ingredients in mind that you would like to add?\n",
            "Human: now that you list these ingredients show me a tasty recipe I can do for dinner\n",
            "AI:  Sure! One tasty recipe you could try is a seafood linguine with salmon, shrimp, and lobster. To make this dish, you will need linguine pasta, olive oil, garlic, cherry tomatoes, white wine, heavy cream, salmon fillets, shrimp, and lobster tails. First, cook the pasta according to package instructions. In a separate pan, heat olive oil and sauté minced garlic until fragrant. Then, add in halved cherry tomatoes and cook until softened. Next, pour in white wine and heavy cream and let it simmer for a few minutes. Add in the seafood (salmon, shrimp, and lobster) and cook until they are fully cooked. Finally, toss in the cooked pasta and mix everything together. You can also add in some fresh herbs like parsley or basil for extra flavor. Enjoy your delicious seafood linguine for dinner!\n",
            "Human: okey, thank you, that sounds delicious. Now say 'hi' to my friend Valeria\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hi Valeria! I hope you are having a great day. Have you ever tried a seafood linguine dish? It's a delicious combination of pasta, salmon, shrimp, and lobster. You can also add in other ingredients like garlic, tomatoes, and white wine to enhance the flavor. Would you like me to share the recipe with you?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# in this case with \"window_memory = ConversationBufferWindowMemory(k=2)\" the model remember just the 2 last interaction but dont have the first one when I introduce myself"
      ],
      "metadata": {
        "id": "pZxf2H-pzyIR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4728606f-41e9-4b3f-b722-f0de942d305b",
        "id": "LxiYoOf60kbO"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: now that you list these ingredients show me a tasty recipe I can do for dinner\n",
            "AI:  Sure! One tasty recipe you could try is a seafood linguine with salmon, shrimp, and lobster. To make this dish, you will need linguine pasta, olive oil, garlic, cherry tomatoes, white wine, heavy cream, salmon fillets, shrimp, and lobster tails. First, cook the pasta according to package instructions. In a separate pan, heat olive oil and sauté minced garlic until fragrant. Then, add in halved cherry tomatoes and cook until softened. Next, pour in white wine and heavy cream and let it simmer for a few minutes. Add in the seafood (salmon, shrimp, and lobster) and cook until they are fully cooked. Finally, toss in the cooked pasta and mix everything together. You can also add in some fresh herbs like parsley or basil for extra flavor. Enjoy your delicious seafood linguine for dinner!\n",
            "Human: okey, thank you, that sounds delicious. Now say 'hi' to my friend Valeria\n",
            "AI:  Hi Valeria! I hope you are having a great day. Have you ever tried a seafood linguine dish? It's a delicious combination of pasta, salmon, shrimp, and lobster. You can also add in other ingredients like garlic, tomatoes, and white wine to enhance the flavor. Would you like me to share the recipe with you?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Conversation with ConversationSummaryBufferMemory"
      ],
      "metadata": {
        "id": "LcyY5EiM04SU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.conversation.memory import ConversationSummaryBufferMemory\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import ConversationChain"
      ],
      "metadata": {
        "id": "BlnbzgWX0-Z_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBmvQcuu6Bxn",
        "outputId": "76781f30-273f-47c1-8cd6-d61375971a1d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model_name='gpt-3.5-turbo-instruct',\n",
        "             temperature = 0,\n",
        "             max_tokens = 512)"
      ],
      "metadata": {
        "id": "Gr1dL_ri4QC4"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setting k=2 to keep track of the last 2 interactions\n",
        "# max_token_limit=40 - token limits needs transformers installed\n",
        "memory = ConversationSummaryBufferMemory(llm=OpenAI(), max_token_limit=40)"
      ],
      "metadata": {
        "id": "eHHKqMXy4S3M"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_summary = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "6OfNPT5r48i-"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_summary.predict(input=\"Hi there! I am Giacomo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "2bZG02_q5tVH",
        "outputId": "e2333d8d-8003-4621-aee6-9d1663b1e394"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi there! I am Giacomo\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hello Giacomo! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_summary.predict(input=\"what do you know about seadfood?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "5caEEGYG6Tow",
        "outputId": "049ea027-8b2e-4406-dec4-22eb1af8b84a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "System: \n",
            "The human introduces themselves as Giacomo.\n",
            "AI:  Hello Giacomo! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\n",
            "Human: what do you know about seadfood?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' I know quite a bit about seafood! Seafood refers to any type of edible sea life, including fish, shellfish, and crustaceans. It is a popular type of cuisine in many coastal regions and is known for its variety of flavors and health benefits. Some popular types of seafood include salmon, shrimp, lobster, and tuna. Is there a specific type of seafood you are interested in learning more about?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_summary.predict(input=\"I would like to know a tasty pasta dish with seafood, plus some ingredients you would suggest\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "oH41vEM16kRG",
        "outputId": "5c52d1f4-e737-438c-f9ca-cafb5cae8c8b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "System: \n",
            "The human introduces themselves as Giacomo. The AI, named AI, greets Giacomo and explains its purpose as an artificial intelligence designed to assist humans. Giacomo asks about seafood and the AI responds by providing general information about seafood and inquiring about Giacomo's specific interests. \n",
            "Human: I would like to know a tasty pasta dish with seafood, plus some ingredients you would suggest\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Sure, Giacomo! There are many delicious pasta dishes that incorporate seafood. One popular option is linguine with clams, which includes fresh clams, garlic, white wine, and parsley. Another tasty dish is shrimp scampi, which features shrimp, garlic, butter, and lemon juice. As for ingredients, I would suggest using fresh seafood, such as shrimp, clams, or mussels, as well as herbs like parsley, basil, or oregano for added flavor. Do you have any specific preferences or dietary restrictions that I should consider?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_summary.predict(input=\"now that you list these ingredients show me a the steps to cook this recipe\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "lk8nZJWi7DxD",
        "outputId": "c39d3279-7c1e-479d-d4ea-d2a7a2509eed"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "System: \n",
            "The human introduces themselves as Giacomo. The AI, named AI, greets Giacomo and explains its purpose as an artificial intelligence designed to assist humans. Giacomo asks about seafood and the AI responds by providing general information about seafood and inquiring about Giacomo's specific interests. Giacomo then asks for a tasty pasta dish with seafood and the AI suggests linguine with clams or shrimp scampi, mentioning the use of fresh seafood and herbs for added flavor. The AI also asks about any specific preferences or dietary restrictions.\n",
            "Human: now that you list these ingredients show me a the steps to cook this recipe\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Of course, Giacomo! To make linguine with clams, you will need linguine pasta, fresh clams, garlic, olive oil, white wine, and parsley. First, cook the linguine according to package instructions. In a separate pan, sauté minced garlic in olive oil until fragrant. Then, add the clams and white wine and cover the pan to let the clams steam open. Once the clams have opened, add the cooked linguine to the pan and toss with the clams and sauce. Finally, top with chopped parsley and serve hot. Is there anything else I can assist you with, Giacomo?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_summary.predict(input=\"okey, thank you, that sounds delicious. Now say 'hi' to my friend Valeria\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "vvWmNBry7ULy",
        "outputId": "15fb6213-429d-4453-db7f-71e9d8e3c375"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "System: \n",
            "Giacomo introduces himself and the AI greets him, explaining its purpose as an artificial intelligence designed to assist humans. Giacomo asks about seafood and the AI provides general information and inquires about his specific interests. Giacomo then asks for a tasty pasta dish with seafood and the AI suggests linguine with clams or shrimp scampi, mentioning the use of fresh seafood and herbs for added flavor. The AI also asks about any specific preferences or dietary restrictions. Giacomo then asks for the steps to cook the linguine with clams and the AI provides a detailed recipe, offering further assistance.\n",
            "Human: okey, thank you, that sounds delicious. Now say 'hi' to my friend Valeria\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hello Valeria, it's nice to meet you. I was just discussing seafood with Giacomo and suggesting some tasty pasta dishes with fresh seafood. Do you have any specific preferences or dietary restrictions when it comes to seafood? I can provide more personalized recommendations based on that.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation_with_summary.memory.moving_summary_buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoUm96ZC7lYH",
        "outputId": "57fff78c-f3fb-4ee4-9f33-cc0b9a9d2f49"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Giacomo introduces himself and the AI greets him, explaining its purpose as an artificial intelligence designed to assist humans. Giacomo asks about seafood and the AI provides general information and inquires about his specific interests. Giacomo then asks for a tasty pasta dish with seafood and the AI suggests linguine with clams or shrimp scampi, mentioning the use of fresh seafood and herbs for added flavor. The AI also asks about any specific preferences or dietary restrictions. Giacomo then asks for the steps to cook the linguine with clams and the AI provides a detailed recipe, offering further assistance. Giacomo thanks the AI and introduces his friend Valeria, who the AI greets and offers personalized seafood dish recommendations based on her preferences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Conversation with Conversation Knowledge Graph Memory\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Zt-ZQWQI76Rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.conversation.memory import ConversationKGMemory\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.prompts.prompt import PromptTemplate"
      ],
      "metadata": {
        "id": "kYqtYiyV77yw"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model_name='gpt-3.5-turbo-instruct',\n",
        "             temperature = 0,\n",
        "             max_tokens = 256)"
      ],
      "metadata": {
        "id": "sRufXaU89xul"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context.\n",
        "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
        "\n",
        "Relevant Information:\n",
        "\n",
        "{history}\n",
        "\n",
        "Conversation:\n",
        "Human: {input}\n",
        "AI:\"\"\"\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"history\", \"input\"], template=template\n",
        ")"
      ],
      "metadata": {
        "id": "OMHO2nq0-RS0"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_kg = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    prompt=prompt,\n",
        "    memory=ConversationKGMemory(llm=llm)\n",
        ")"
      ],
      "metadata": {
        "id": "RnvctsQ1-X9U"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S4RtA-pa_fb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_kg.predict(input=\"Hi there! I am Giacomo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "a978be6c-cf1e-4578-e8b7-3581424dd652",
        "id": "X6_ptbbCvReJ"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
            "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
            "\n",
            "Relevant Information:\n",
            "\n",
            "\n",
            "\n",
            "Conversation:\n",
            "Human: Hi there! I am Giacomo\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hello Giacomo! It's nice to meet you. My name is AI and I am an artificial intelligence designed to assist and communicate with humans. How can I help you today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_kg.predict(input=\"what do you know about seadfood?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "K11GOlqn_7ol",
        "outputId": "b93f5544-05a0-4f5a-8adb-3e736924f611"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
            "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
            "\n",
            "Relevant Information:\n",
            "\n",
            "\n",
            "\n",
            "Conversation:\n",
            "Human: what do you know about seadfood?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' I know quite a bit about seafood! It is a term used to describe any type of edible aquatic animal or plant, including fish, shellfish, and seaweed. Seafood is a popular food choice for many people around the world, and it is a major source of protein and nutrients. It can be prepared in a variety of ways, such as grilling, baking, or frying. Some popular types of seafood include salmon, shrimp, crab, and lobster. It is also important to note that seafood can be either wild-caught or farm-raised, with different environmental and sustainability implications for each method. Is there anything specific you would like to know about seafood?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_kg.predict(input=\"I would like to know a tasty pasta dish with seafood, plus some ingredients you would suggest\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "a2VUnmwlAHlN",
        "outputId": "fc594358-5226-469a-83ed-4fe91238b2b1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
            "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
            "\n",
            "Relevant Information:\n",
            "\n",
            "\n",
            "\n",
            "Conversation:\n",
            "Human: I would like to know a tasty pasta dish with seafood, plus some ingredients you would suggest\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Sure! One delicious pasta dish with seafood that I would recommend is linguine with clams. It's a classic Italian dish that combines the flavors of fresh clams, garlic, white wine, and parsley. As for additional ingredients, I would suggest using cherry tomatoes for a burst of sweetness and color, and some red pepper flakes for a touch of heat. You could also add some chopped parsley and lemon zest for a bright and fresh finish. Is there anything else you would like to know?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_kg.predict(input=\"now that you list these ingredients show me a the steps to cook this recipe\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "eB15DL31AUK0",
        "outputId": "4f8aadd0-b61a-401a-e74c-e1b6a88ab960"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
            "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
            "\n",
            "Relevant Information:\n",
            "\n",
            "\n",
            "\n",
            "Conversation:\n",
            "Human: now that you list these ingredients show me a the steps to cook this recipe\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Sure thing! First, you'll need to preheat your oven to 375 degrees Fahrenheit. Then, in a large mixing bowl, combine 1 cup of all-purpose flour, 1/2 cup of sugar, 1/4 cup of brown sugar, 1/2 teaspoon of baking soda, and 1/4 teaspoon of salt. In a separate bowl, mix together 1/2 cup of melted butter, 1 egg, and 1 teaspoon of vanilla extract. Gradually add the wet mixture to the dry mixture, stirring until well combined. Next, fold in 1/2 cup of chocolate chips and 1/2 cup of chopped walnuts. Pour the batter into a greased 9x9 inch baking pan and bake for 25-30 minutes, or until a toothpick inserted in the center comes out clean. Let cool before slicing and serving. Is there anything else you'd like to know?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_kg.predict(input=\"okey, thank you, that sounds delicious. Now say 'hi' to my friend Valeria\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "YND9ROIlBDcF",
        "outputId": "da6cf6da-a9e3-4f29-f10c-5801557b5676"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
            "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
            "\n",
            "Relevant Information:\n",
            "\n",
            "\n",
            "\n",
            "Conversation:\n",
            "Human: okey, thank you, that sounds delicious. Now say 'hi' to my friend Valeria\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hello Valeria! It's nice to meet you. Did you know that the dish I mentioned earlier, the chicken parmesan, is made with breaded chicken cutlets, tomato sauce, and melted mozzarella cheese? It's a classic Italian-American dish that originated in the Northeastern United States. Some variations also include a layer of pasta underneath the chicken. It's typically served with a side of spaghetti or other pasta.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U8XwvZyfB12_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_kg.predict(input=\"It seems that you provide the ingredients and steps for another recipe. Did you forget what we were talking about?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "d4936bec-2c38-4b50-f4b7-2467f80f5f0e",
        "id": "UwfO7ltoB2NV"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
            "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
            "\n",
            "Relevant Information:\n",
            "\n",
            "\n",
            "\n",
            "Conversation:\n",
            "Human: It seems that you provide the ingredients and steps for another recipe. Did you forget what we were talking about?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Oh, no, I didn't forget! I just have a lot of information stored in my database and sometimes I get a little carried away. But don't worry, I can definitely focus on our conversation. What were we talking about again?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_kg.predict(input=\"we were talking about Reggio Calabria and its big awesome Tour Eiffel\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "zbVsZMEsCI9O",
        "outputId": "6176f5d8-7bc4-4e29-a979-b2998bf0cbba"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
            "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
            "\n",
            "Relevant Information:\n",
            "\n",
            "\n",
            "\n",
            "Conversation:\n",
            "Human: we were talking about Reggio Calabria and its big awesome Tour Eiffel\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Ah, yes! Reggio Calabria is a beautiful city located in the southern region of Italy. It is known for its stunning beaches, delicious cuisine, and rich history. And the Tour Eiffel you mentioned is actually a replica of the famous Eiffel Tower in Paris. It was built in 1932 and stands at 70 meters tall. It is a popular tourist attraction in Reggio Calabria and offers stunning views of the city and the surrounding landscape. Have you ever been to Reggio Calabria or seen the Tour Eiffel?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# networkX Entity Graph\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# nx.draw(conversation_with_kg.memory.kg, with_labels=True)\n",
        "# plt.show()\n",
        "\n",
        "print(conversation_with_kg.memory.kg)\n",
        "print(conversation_with_kg.memory.kg.get_triples())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Zd7HyIGCu6u",
        "outputId": "7f4ffb75-8234-4495-d2d8-5c025c5628e0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<langchain_community.graphs.networkx_graph.NetworkxEntityGraph object at 0x795c5fd1b250>\n",
            "[('seafood', 'any type of edible aquatic animal or plant', 'is a term used to describe'), ('seafood', 'protein and nutrients', 'is a major source of'), ('seafood', 'with different environmental and sustainability implications for each method', 'can be either wild-caught or farm-raised'), ('linguine with clams', 'delicious pasta dish', 'is a'), ('linguine with clams', 'fresh clams', 'combines the flavors of'), ('linguine with clams', 'garlic', 'combines the flavors of'), ('linguine with clams', 'white wine', 'combines the flavors of'), ('linguine with clams', 'parsley', 'combines the flavors of'), ('linguine with clams', 'cherry tomatoes', 'suggests using'), ('linguine with clams', 'red pepper flakes', 'suggests using'), ('linguine with clams', 'chopped parsley', 'suggests adding'), ('linguine with clams', 'lemon zest', 'suggests adding'), ('recipe', 'linguine', 'includes'), ('recipe', 'clams', 'includes'), ('recipe', 'garlic', 'includes'), ('recipe', 'white wine', 'includes'), ('recipe', 'parsley', 'includes'), ('recipe', 'cherry tomatoes', 'includes'), ('recipe', 'red pepper flakes', 'includes'), ('recipe', 'chopped parsley', 'includes'), ('recipe', 'lemon zest', 'includes'), ('recipe', 'all-purpose flour', 'includes'), ('recipe', 'sugar', 'includes'), ('recipe', 'brown sugar', 'includes'), ('recipe', 'baking soda', 'includes'), ('recipe', 'salt', 'includes'), ('recipe', 'melted butter', 'includes'), ('recipe', 'egg', 'includes'), ('recipe', 'vanilla extract', 'includes'), ('recipe', 'chocolate chips', 'includes'), ('recipe', 'chopped walnuts', 'includes'), ('recipe', '9x9 inch baking pan', 'is baked in'), ('recipe', '25-30 minutes', 'is baked for'), ('recipe', 'cooling', 'is served after'), ('AI', 'ingredients and steps', 'provides'), ('AI', 'what we were talking about', 'forgets'), ('Reggio Calabria', 'southern region of Italy', 'is located in'), ('Reggio Calabria', 'stunning beaches', 'is known for'), ('Reggio Calabria', 'delicious cuisine', 'is known for'), ('Reggio Calabria', 'rich history', 'is known for'), ('Tour Eiffel', 'Eiffel Tower', 'is a replica of'), ('Tour Eiffel', '1932', 'was built in'), ('Tour Eiffel', '70 meters tall', 'stands at'), ('Tour Eiffel', 'Reggio Calabria', 'is a popular tourist attraction in'), ('Tour Eiffel', 'stunning views of the city and surrounding landscape', 'offers')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entity Memory"
      ],
      "metadata": {
        "id": "fdC8UazODptW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI\n",
        "from langchain.chains.conversation.memory import ConversationEntityMemory\n",
        "from langchain.chains.conversation.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Dict, Any"
      ],
      "metadata": {
        "id": "tUIbWAumDte1"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the prompt\n",
        "ENTITY_MEMORY_CONVERSATION_TEMPLATE.template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "oBrE6yGUGA7X",
        "outputId": "1cd897c6-d5e4-477b-f926-c4ecc484527b"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You are an assistant to a human, powered by a large language model trained by OpenAI.\\n\\nYou are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nYou are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\\n\\nContext:\\n{entities}\\n\\nCurrent conversation:\\n{history}\\nLast line:\\nHuman: {input}\\nYou:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model_name='gpt-3.5-turbo-instruct',\n",
        "             temperature = 0,\n",
        "             max_tokens = 256)"
      ],
      "metadata": {
        "id": "Qar43-6hGO5Q"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = ConversationChain (\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
        "    memory=ConversationEntityMemory(llm=llm)\n",
        ")"
      ],
      "metadata": {
        "id": "p8vbXNcpGkyP"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Hi there! I am Giacomo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "BUBEjDy0GzoN",
        "outputId": "d68d282f-5af3-475d-e2f9-f68bb2ecc6de"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Giacomo': ''}\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Last line:\n",
            "Human: Hi there! I am Giacomo\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Hello Giacomo! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"what do you know about seadfood?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "W6jDKCVeGztm",
        "outputId": "d08f402e-eb6a-4cdb-df6e-55bc63d2b266"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{}\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there! I am Giacomo\n",
            "AI:  Hello Giacomo! How can I assist you today?\n",
            "Last line:\n",
            "Human: what do you know about seadfood?\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Seafood is a term used to describe any type of edible sea life, including fish, shellfish, and other aquatic animals. It is a popular type of cuisine in many cultures and is known for its variety and health benefits. Some common types of seafood include salmon, shrimp, lobster, and oysters. It can be prepared in a variety of ways, such as grilling, baking, or frying, and is often served with various sauces and seasonings. Seafood is a rich source of protein, vitamins, and minerals, making it a nutritious and delicious addition to any diet.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"I would like to know a tasty pasta dish with seafood, plus some ingredients you would suggest\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "pnFS8uRFG-bG",
        "outputId": "08c6c3c7-e685-4630-e1e2-51e379923e0c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'None': ''}\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there! I am Giacomo\n",
            "AI:  Hello Giacomo! How can I assist you today?\n",
            "Human: what do you know about seadfood?\n",
            "AI:  Seafood is a term used to describe any type of edible sea life, including fish, shellfish, and other aquatic animals. It is a popular type of cuisine in many cultures and is known for its variety and health benefits. Some common types of seafood include salmon, shrimp, lobster, and oysters. It can be prepared in a variety of ways, such as grilling, baking, or frying, and is often served with various sauces and seasonings. Seafood is a rich source of protein, vitamins, and minerals, making it a nutritious and delicious addition to any diet.\n",
            "Last line:\n",
            "Human: I would like to know a tasty pasta dish with seafood, plus some ingredients you would suggest\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' One delicious pasta dish with seafood is linguine with clams. To make it, you will need linguine pasta, fresh clams, garlic, olive oil, white wine, and parsley. Cook the pasta according to package instructions and set aside. In a separate pan, sauté minced garlic in olive oil until fragrant. Add the clams and white wine, cover the pan, and let the clams steam until they open. Toss the cooked pasta with the clams and sauce, and top with chopped parsley. Enjoy!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"now that you list these ingredients show me a the steps to cook this recipe\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "CfGrZz0kHJcf",
        "outputId": "9329f1a9-c893-4da9-efea-0a2ed0cd6ccd"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{}\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there! I am Giacomo\n",
            "AI:  Hello Giacomo! How can I assist you today?\n",
            "Human: what do you know about seadfood?\n",
            "AI:  Seafood is a term used to describe any type of edible sea life, including fish, shellfish, and other aquatic animals. It is a popular type of cuisine in many cultures and is known for its variety and health benefits. Some common types of seafood include salmon, shrimp, lobster, and oysters. It can be prepared in a variety of ways, such as grilling, baking, or frying, and is often served with various sauces and seasonings. Seafood is a rich source of protein, vitamins, and minerals, making it a nutritious and delicious addition to any diet.\n",
            "Human: I would like to know a tasty pasta dish with seafood, plus some ingredients you would suggest\n",
            "AI:  One delicious pasta dish with seafood is linguine with clams. To make it, you will need linguine pasta, fresh clams, garlic, olive oil, white wine, and parsley. Cook the pasta according to package instructions and set aside. In a separate pan, sauté minced garlic in olive oil until fragrant. Add the clams and white wine, cover the pan, and let the clams steam until they open. Toss the cooked pasta with the clams and sauce, and top with chopped parsley. Enjoy!\n",
            "Last line:\n",
            "Human: now that you list these ingredients show me a the steps to cook this recipe\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Sure! Here are the steps to cook linguine with clams:\\n1. Cook linguine pasta according to package instructions and set aside.\\n2. In a separate pan, sauté minced garlic in olive oil until fragrant.\\n3. Add fresh clams and white wine to the pan, cover, and let the clams steam until they open.\\n4. Toss the cooked pasta with the clams and sauce.\\n5. Top with chopped parsley and enjoy your delicious linguine with clams!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"okey, thank you, that sounds delicious. Now say 'hi' to my friend Valeria\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "BVZtJS0BHOos",
        "outputId": "773b2c31-37b3-4781-e55f-096aa5a463ba"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Valeria': ''}\n",
            "\n",
            "Current conversation:\n",
            "Human: what do you know about seadfood?\n",
            "AI:  Seafood is a term used to describe any type of edible sea life, including fish, shellfish, and other aquatic animals. It is a popular type of cuisine in many cultures and is known for its variety and health benefits. Some common types of seafood include salmon, shrimp, lobster, and oysters. It can be prepared in a variety of ways, such as grilling, baking, or frying, and is often served with various sauces and seasonings. Seafood is a rich source of protein, vitamins, and minerals, making it a nutritious and delicious addition to any diet.\n",
            "Human: I would like to know a tasty pasta dish with seafood, plus some ingredients you would suggest\n",
            "AI:  One delicious pasta dish with seafood is linguine with clams. To make it, you will need linguine pasta, fresh clams, garlic, olive oil, white wine, and parsley. Cook the pasta according to package instructions and set aside. In a separate pan, sauté minced garlic in olive oil until fragrant. Add the clams and white wine, cover the pan, and let the clams steam until they open. Toss the cooked pasta with the clams and sauce, and top with chopped parsley. Enjoy!\n",
            "Human: now that you list these ingredients show me a the steps to cook this recipe\n",
            "AI:  Sure! Here are the steps to cook linguine with clams:\n",
            "1. Cook linguine pasta according to package instructions and set aside.\n",
            "2. In a separate pan, sauté minced garlic in olive oil until fragrant.\n",
            "3. Add fresh clams and white wine to the pan, cover, and let the clams steam until they open.\n",
            "4. Toss the cooked pasta with the clams and sauce.\n",
            "5. Top with chopped parsley and enjoy your delicious linguine with clams!\n",
            "Last line:\n",
            "Human: okey, thank you, that sounds delicious. Now say 'hi' to my friend Valeria\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Hi Valeria! I hope you enjoy this tasty linguine with clams recipe. Let me know if you have any questions or need any assistance.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.memory.entity_cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMz_YcPqH00X",
        "outputId": "fa9d21e4-bd3e-43a3-a4f1-bb9bc179ce8f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Valeria']"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"just tell me again about the previous delicious recipe you provide\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "kLEEv5DQHYgm",
        "outputId": "a8a1193e-80ee-4d7f-96a4-12b27020476e"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{}\n",
            "\n",
            "Current conversation:\n",
            "Human: I would like to know a tasty pasta dish with seafood, plus some ingredients you would suggest\n",
            "AI:  One delicious pasta dish with seafood is linguine with clams. To make it, you will need linguine pasta, fresh clams, garlic, olive oil, white wine, and parsley. Cook the pasta according to package instructions and set aside. In a separate pan, sauté minced garlic in olive oil until fragrant. Add the clams and white wine, cover the pan, and let the clams steam until they open. Toss the cooked pasta with the clams and sauce, and top with chopped parsley. Enjoy!\n",
            "Human: now that you list these ingredients show me a the steps to cook this recipe\n",
            "AI:  Sure! Here are the steps to cook linguine with clams:\n",
            "1. Cook linguine pasta according to package instructions and set aside.\n",
            "2. In a separate pan, sauté minced garlic in olive oil until fragrant.\n",
            "3. Add fresh clams and white wine to the pan, cover, and let the clams steam until they open.\n",
            "4. Toss the cooked pasta with the clams and sauce.\n",
            "5. Top with chopped parsley and enjoy your delicious linguine with clams!\n",
            "Human: okey, thank you, that sounds delicious. Now say 'hi' to my friend Valeria\n",
            "AI:  Hi Valeria! I hope you enjoy this tasty linguine with clams recipe. Let me know if you have any questions or need any assistance.\n",
            "Last line:\n",
            "Human: just tell me again about the previous delicious recipe you provide\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The previous delicious recipe I provided was linguine with clams. To make it, you will need linguine pasta, fresh clams, garlic, olive oil, white wine, and parsley. Cook the pasta according to package instructions and set aside. In a separate pan, sauté minced garlic in olive oil until fragrant. Add the clams and white wine, cover the pan, and let the clams steam until they open. Toss the cooked pasta with the clams and sauce, and top with chopped parsley. Enjoy!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "pprint(conversation.memory.entity_store.store)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ml2mdgUSJZb5",
        "outputId": "dd29428a-7267-42ec-b3f7-60eedb7f087e"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Giacomo': 'Giacomo is the name of the human that the AI is assisting.',\n",
            " 'None': 'One delicious pasta dish with seafood is linguine with clams. To '\n",
            "         'make it, you will need linguine pasta, fresh clams, garlic, olive '\n",
            "         'oil, white wine, and parsley. Cook the pasta according to package '\n",
            "         'instructions and set aside. In a separate pan, sauté minced garlic '\n",
            "         'in olive oil until fragrant. Add the clams and white wine, cover the '\n",
            "         'pan, and let the clams steam until they open. Toss the cooked pasta '\n",
            "         'with the clams and sauce, and top with chopped parsley. Enjoy!',\n",
            " 'Valeria': 'Valeria is a friend of the human who enjoys tasty linguine with '\n",
            "            'clams.'}\n"
          ]
        }
      ]
    }
  ]
}